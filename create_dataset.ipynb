{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to build dataset out of labeled soundfiles, consisting of spectograms to train and validate learner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in Laufwerk C: hat keine Bezeichnung.\n",
      " Volumeseriennummer: 46FB-03FE\n",
      "\n",
      " Verzeichnis von C:\\Users\\paulo\\Coding\\techlabsms-project-PredictivePollution\n",
      "\n",
      "27.03.2021  17:43    <DIR>          .\n",
      "27.03.2021  17:43    <DIR>          ..\n",
      "06.09.2019  19:38             1.203 .gitignore\n",
      "27.03.2021  16:58    <DIR>          .ipynb_checkpoints\n",
      "27.03.2021  17:35         3.594.161 bg_lr_v2_5s_analyse.ipynb\n",
      "27.03.2021  17:26            10.836 copy_engine_from_ESC-50.ipynb\n",
      "27.03.2021  17:42            47.444 create_dataset.ipynb\n",
      "27.03.2021  17:34             7.478 create_spectogram.ipynb\n",
      "27.03.2021  17:41    <DIR>          datasets\n",
      "27.03.2021  17:31             4.894 edit_soundfiles.ipynb\n",
      "27.03.2021  17:26    <DIR>          ESC-50-master\n",
      "27.03.2021  16:58           303.131 evaluation_learner_v2.ipynb\n",
      "27.03.2021  16:58         1.268.986 learner_v1.ipynb\n",
      "27.03.2021  16:58           724.533 learner_v2.ipynb\n",
      "27.03.2021  16:58            10.078 merge_dataframes.ipynb\n",
      "27.03.2021  17:41    <DIR>          pp_raw_data\n",
      "06.09.2019  19:38                78 README.md\n",
      "27.03.2021  17:43    <DIR>          temp\n",
      "              11 Datei(en),      5.972.822 Bytes\n",
      "               7 Verzeichnis(se), 845.953.064.960 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import pydub\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "import pylab\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram(source_filepath, destination_filepath):    \n",
    "    y, sr = librosa.load(source_filepath, sr = 22050) # Use the default sampling rate of 22,050 Hz\n",
    "\n",
    "    # Pre-emphasis filter\n",
    "    pre_emphasis = 0.97\n",
    "    y = np.append(y[0], y[1:] - pre_emphasis * y[:-1])\n",
    "\n",
    "    # Compute spectrogram\n",
    "    M = librosa.feature.melspectrogram(y, \n",
    "                                       sr, \n",
    "                                       fmax = sr/2, # Maximum frequency to be used on the on the MEL scale        \n",
    "                                       n_fft=2048, \n",
    "                                       hop_length=512, \n",
    "                                       n_mels = 96, # As per the Google Large-scale audio CNN paper\n",
    "                                       power = 2) # Power = 2 refers to squared amplitude\n",
    "    # Power in DB\n",
    "    log_power = librosa.power_to_db(M, ref=np.max)# Covert to dB (log) scale\n",
    "\n",
    "    # Plotting the spectrogram and save as JPG without axes (just the image)\n",
    "    pylab.figure(figsize=(5,5)) #was 14, 5\n",
    "    pylab.axis('off') \n",
    "    pylab.axes([0., 0., 1., 1.], frameon=False, xticks=[], yticks=[]) # Remove the white edge\n",
    "    librosa.display.specshow(log_power, cmap=cm.jet)\n",
    "\n",
    "    pylab.savefig(destination_filepath, bbox_inches=None, pad_inches=0)\n",
    "    pylab.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_save(tgt_size, src_file, tgt_folder):\n",
    "    \n",
    "    \n",
    "    if str(src_file)[-4:] == '.wav':\n",
    "        soundf = pydub.AudioSegment.from_wav(src_file)\n",
    "        fmt = 'wav'\n",
    "\n",
    "    if str(src_file)[-4:] == '.mp3':\n",
    "        soundf = pydub.AudioSegment.from_mp3(src_file)\n",
    "        fmt = 'mp3'\n",
    "    #soundf = pydub.AudioSegment.from_wav(src_file) #aktuell nur wav files -> mit if abfrage noch für mp3 anpassen\n",
    "    for i, chunk in enumerate(soundf[::tgt_size]):\n",
    "        #print(len(chunk))\n",
    "        if len(chunk) == tgt_size: #soundfile wird nur gespeichert wenn es der target size entspricht --> letztes file wird verworfen wenn es zu kurz ist. Kann man sicher noch elleganter lösen in dem man letztes file mit leerer datei auffült oderso\n",
    "            with open(tgt_folder + os.path.basename(src_file)[:-4] + \"_%s.wav\" % (i+1), \"wb\") as f:    \n",
    "                chunk.export(f, format= 'wav')\n",
    "                \n",
    "    return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sflen(pth):\n",
    "    if str(pth)[-4:] == '.wav':\n",
    "        soundf = pydub.AudioSegment.from_wav(pth)\n",
    "        sflen = len(soundf)\n",
    "    elif str(pth)[-4:] == '.mp3':\n",
    "        soundf = pydub.AudioSegment.from_mp3(pth)\n",
    "        sflen = len(soundf)\n",
    "    else:\n",
    "        sflen = 0\n",
    "        print(\"Warning: at least one file don't has valid datatype\")\n",
    "        \n",
    "    return sflen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    #class initialization\n",
    "    def __init__(self, folderpath):\n",
    "        self.pathlen = len(folderpath)\n",
    "        self.folderpath = Path(folderpath)\n",
    "        self.flst = list(self.folderpath.iterdir())\n",
    "        self.lendict_p = {str(o)[:] : sflen(str(o)) for o in self.flst}\n",
    "        self.lendict = {str(o)[len(folderpath):] : sflen(str(o)) for o in self.flst}\n",
    "        self.lendf = pd.DataFrame({'soundfilelength' : self.lendict}) \n",
    "        \n",
    "    #general information \n",
    "    def info(self):\n",
    "        #return len(list(self.folderpath.iterdir()))\n",
    "        print(\"Number of files: \" + str(len(self.flst)))\n",
    "        print('Overall length: '+ str(self.lendf['soundfilelength'].sum()) + \" ms\")\n",
    "        print('Max file length: '+ str(self.lendf['soundfilelength'].max()) + \" ms\")\n",
    "        print('Min file length: '+ str(self.lendf['soundfilelength'].min()) + \" ms\")\n",
    "        print('mean file length: '+ str(self.lendf['soundfilelength'].mean()) + \" ms\")\n",
    "    \n",
    "    #return list of all files \n",
    "    def filelist(self):\n",
    "        return self.flst\n",
    "    \n",
    "    #return length of soundfiles\n",
    "    def oalen(self):\n",
    "        oalen = self.lendf['soundfilelength'].sum()\n",
    "        #for i in self.filelist():\n",
    "         #   if str(i)[-3:] == 'wav':\n",
    "          #      soundf = pydub.AudioSegment.from_wav(i)\n",
    "           #     oalen = oalen + len(soundf)\n",
    "            #if str(i)[-3:] == 'mp3':\n",
    "             #   soundf = pydub.AudioSegment.from_mp3(i)\n",
    "              #  oalen = oalen + len(soundf)\n",
    "        return oalen\n",
    "    \n",
    "    #return longest soundfile\n",
    "    def maxfile(self):\n",
    "        maxfile = self.lendf['soundfilelength'].idxmax()\n",
    "        return maxfile\n",
    "    \n",
    "    #return shortest soundfile\n",
    "    def minfile(self):\n",
    "        minfile = self.lendf['soundfilelength'].idxmin()\n",
    "        return minfile\n",
    "    \n",
    "    #convert files to spectogram\n",
    "    def convert_all(self, destination_filepath): #konvertiert alle files im ordner so wie sie sind zu spectrogrammen\n",
    "        x = 1\n",
    "        for i in self.flst:\n",
    "            create_spectrogram(str(i), destination_filepath + str(i)[data1.pathlen:-4] + \".jpg\")\n",
    "            x = x +1\n",
    "        print(\"converted \" + str(x) + \" files to spectrogram\")\n",
    "        \n",
    "    #cut files into parts\n",
    "    def split_all(self, tgt_size, tgt_folder):\n",
    "        \n",
    "        for i in self.flst:\n",
    "            split_and_save(tgt_size, str(i), tgt_folder)\n",
    "            \n",
    "    # combine splitting and converting     \n",
    "    def split_and_convert(self, tgt_size, tgt_folder, csv = False, label = '', ds_label = '' ): #evtl. noch optionale angaben ob man gesplitete soundfiles behalten möchte oder nicht implementieren\n",
    "        if tgt_folder[-1] != '/':\n",
    "            tgt_folder = tgt_folder + '/'\n",
    "        \n",
    "        \n",
    "        if label == '':\n",
    "            print('testprint:' + os.path.basename(tgt_folder[:-1]))\n",
    "            label = os.path.basename(tgt_folder[:-1])\n",
    "\n",
    "        \n",
    "        if ds_label == '':\n",
    "            ds_label = str(os.path.basename(tgt_folder[:-1]))\n",
    "            \n",
    "        \n",
    "        \n",
    "        tempfolder = 'temp/'\n",
    "        #create folder for split files: (PATH).mkdir(exist_ok=True)\n",
    "        if os.path.isdir(tempfolder) == False:\n",
    "            os.makedirs(tempfolder)\n",
    "            \n",
    "        #create folder for spectograms\n",
    "        if os.path.isdir(tgt_folder) == False:\n",
    "            os.makedirs(tgt_folder)\n",
    "            \n",
    "        for i in self.flst:\n",
    "            split_and_save(tgt_size, i, tempfolder)\n",
    "            x = 1\n",
    "            for j in list(Path(tempfolder).iterdir()):\n",
    "                create_spectrogram(str(j), tgt_folder + os.path.basename(str(j))[:-4] + \".jpg\")\n",
    "                x = x +1\n",
    "                os.remove(j)\n",
    "            print(\"converted \" + str(x) + \" files to spectrogram\")  \n",
    "        if csv == True:    \n",
    "            #create dataframe\n",
    "            filelist = list(Path(tgt_folder).iterdir())\n",
    "\n",
    "            labellist = [label] * len(filelist)\n",
    "            ds_labellist = [ds_label] * len(filelist)\n",
    "            pathlist = [os.path.relpath(tgt_folder)] * len(filelist)\n",
    "\n",
    "            df = pd.DataFrame({'Filename' : filelist, 'Label' : labellist, 'DS_Label' : ds_labellist, 'Path' : pathlist})\n",
    "\n",
    "            #clean filenames\n",
    "            for i, row in df.iterrows():\n",
    "                df.loc[i, 'Filename'] = str(os.path.basename(df.loc[i, 'Filename']))\n",
    "\n",
    "            df.to_csv(str(os.path.dirname(tgt_folder) + '.csv'))\n",
    "            print('Path to .csv: ' + str(os.path.dirname(tgt_folder) + '.csv'))\n",
    "        \n",
    "        #return df\n",
    "        \n",
    "    \n",
    "    #files in dataset folder will be split in 3(learn, val und test) according to given formular (e.g. 0.7,0.2,0.1)\n",
    "    def divide_data(self, tgt_dset_path, tgt_dist_learn = 0.7, tgt_dist_val = 0.2, tgt_dist_test = 0.1):\n",
    "        \n",
    "        if round(tgt_dist_learn + tgt_dist_val + tgt_dist_test, 4) != 1.0:\n",
    "            print('sum of inputs are not 100%')\n",
    "            return ()\n",
    "        #calculate ideal distribution\n",
    "        oalength = self.oalen()\n",
    "        \n",
    "        tgt_time_learn = tgt_dist_learn * oalength\n",
    "        tmp_time_learn = 0\n",
    "        tgt_time_val = tgt_dist_val * oalength\n",
    "        tmp_time_val = 0\n",
    "        tgt_time_test = tgt_dist_test * oalength\n",
    "        tmp_time_test = 0\n",
    "        \n",
    "        \n",
    "        #create folders\n",
    "        if os.path.isdir(tgt_dset_path) == False:\n",
    "            os.makedirs(tgt_dset_path)\n",
    "        if os.path.isdir(tgt_dset_path + '/learn') == False:\n",
    "            os.makedirs(tgt_dset_path + '/learn')\n",
    "        if os.path.isdir(tgt_dset_path + '/val') == False:\n",
    "            os.makedirs(tgt_dset_path + '/val')\n",
    "        if os.path.isdir(tgt_dset_path + '/test') == False:\n",
    "            os.makedirs(tgt_dset_path + '/test')\n",
    "            \n",
    "        learnpath = tgt_dset_path + '/learn'\n",
    "        valpath = tgt_dset_path + '/val'\n",
    "        testpath = tgt_dset_path + '/test'\n",
    "        \n",
    "        def dt_learn():\n",
    "            return tmp_time_learn/(tgt_time_learn/100)\n",
    "        \n",
    "        def dt_val():\n",
    "            return tmp_time_val/(tgt_time_val/100)\n",
    "        \n",
    "        def dt_test():\n",
    "            return tmp_time_test/(tgt_time_test/100)\n",
    "        \n",
    "        #create random list\n",
    "        randomlist = list(self.filelist())\n",
    "        random.shuffle(randomlist)\n",
    "        \n",
    "        #go through random list and copy to folder with the biggest error/delta\n",
    "        for i in randomlist:\n",
    "            if (dt_learn() < 100) and (dt_learn() <= dt_val()) and (dt_learn() <= dt_test()):\n",
    "                shutil.copy(i, learnpath)\n",
    "                tmp_time_learn = tmp_time_learn + self.lendict_p[str(i)]\n",
    "                \n",
    "                \n",
    "            elif (dt_val() < 100) and (dt_val() <= dt_learn()) and (dt_val() <= dt_test()):\n",
    "                shutil.copy(i, valpath)\n",
    "                tmp_time_val = tmp_time_val + self.lendict_p[str(i)]\n",
    "                \n",
    "            elif (dt_test() < 100) and (dt_test() <= dt_val()) and (dt_test() <= dt_learn()):\n",
    "                shutil.copy(i, testpath)\n",
    "                tmp_time_test = tmp_time_test + self.lendict_p[str(i)]\n",
    "                \n",
    "        print('error learn: ' + str(round(dt_learn() - 100, 2)) + '%; error val: ' + str(round(dt_val() - 100, 2)) + '%; error test: ' + str(round(dt_test() - 100, 2)) + '%;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_path_benzin = 'C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/benzin_div'\n",
    "divide_path_diesel = 'C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data_div/diesel_div'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "benzin_train = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/benzin_div/learn')\n",
    "benzin_valid = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/benzin_div/val')\n",
    "benzin_test = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/benzin_div/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "diesel_train = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/diesel_div/learn')\n",
    "diesel_valid = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/diesel_div/val')\n",
    "diesel_test = Dataset('C:/Users/paulo/Coding/techlabsms-project-PredictivePollution/pp_raw_data/pp_raw_data_div/diesel_div/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 0\n",
      "Overall length: 0.0 ms\n",
      "Max file length: nan ms\n",
      "Min file length: nan ms\n",
      "mean file length: nan ms\n"
     ]
    }
   ],
   "source": [
    "benzin_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3bc6c21af56e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbenzin_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-30872e476aa8>\u001b[0m in \u001b[0;36mminfile\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#gibt kürzestes Soundfile aus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mminfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mminfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlendf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'soundfilelength'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mminfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36midxmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2095\u001b[0m         \"\"\"\n\u001b[0;32m   2096\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_argmin_with_skipna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2097\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2098\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanargmin\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \"\"\"\n\u001b[0;32m    967\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"+inf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "benzin_train.minfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 0\n",
      "Overall length: 0.0 ms\n",
      "Max file length: nan ms\n",
      "Min file length: nan ms\n",
      "mean file length: nan ms\n"
     ]
    }
   ],
   "source": [
    "benzin_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/dbsacc.mp3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benzin_valid.minfile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 47\n",
      "Overall length: 2136916 ms\n",
      "Max file length: 770972 ms\n",
      "Min file length: 6991 ms\n",
      "mean file length: 45466.29787234042 ms\n"
     ]
    }
   ],
   "source": [
    "benzin_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 41\n",
      "Overall length: 13727214 ms\n",
      "Max file length: 3641842 ms\n",
      "Min file length: 5000 ms\n",
      "mean file length: 334810.0975609756 ms\n"
     ]
    }
   ],
   "source": [
    "diesel_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 7\n",
      "Overall length: 4787585 ms\n",
      "Max file length: 1711387 ms\n",
      "Min file length: 5000 ms\n",
      "mean file length: 683940.7142857143 ms\n"
     ]
    }
   ],
   "source": [
    "diesel_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 11\n",
      "Overall length: 2407575 ms\n",
      "Max file length: 1334729 ms\n",
      "Min file length: 5000 ms\n",
      "mean file length: 218870.45454545456 ms\n"
     ]
    }
   ],
   "source": [
    "diesel_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "milliseconds = 1000\n",
    "foldername = 'dataset1_1sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to .csv: datasets/dataset1_1sec/train/benzin.csv\n"
     ]
    }
   ],
   "source": [
    "benzin_train.split_and_convert(milliseconds, ('datasets/' + foldername + '/train/benzin'), csv = True , label = 'benzin', ds_label = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 11 files to spectrogram\n",
      "converted 22 files to spectrogram\n",
      "converted 22 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 25 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 645 files to spectrogram\n",
      "converted 614 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 18 files to spectrogram\n",
      "converted 20 files to spectrogram\n",
      "converted 504 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 10 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 30 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 22 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 20 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 18 files to spectrogram\n",
      "converted 23 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 1200 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 24 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 252 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 28 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 24 files to spectrogram\n",
      "converted 9 files to spectrogram\n",
      "converted 18 files to spectrogram\n",
      "converted 7 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 26 files to spectrogram\n",
      "converted 9 files to spectrogram\n",
      "converted 7 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 25 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 17 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 7 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 10 files to spectrogram\n",
      "converted 20 files to spectrogram\n",
      "converted 9 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 24 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "Path to .csv: datasets/dataset1_1sec/valid/benzin.csv\n"
     ]
    }
   ],
   "source": [
    "benzin_valid.split_and_convert(milliseconds, ('datasets/' + foldername + '/valid/benzin'), csv = True , label = 'benzin', ds_label = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 19 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 17 files to spectrogram\n",
      "converted 706 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 7 files to spectrogram\n",
      "converted 9 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 17 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 38 files to spectrogram\n",
      "converted 27 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 10 files to spectrogram\n",
      "converted 20 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 771 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 17 files to spectrogram\n",
      "converted 10 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 8 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 26 files to spectrogram\n",
      "converted 9 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 16 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 14 files to spectrogram\n",
      "converted 13 files to spectrogram\n",
      "converted 21 files to spectrogram\n",
      "converted 12 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "Path to .csv: datasets/dataset1_1sec/test/benzin.csv\n"
     ]
    }
   ],
   "source": [
    "benzin_test.split_and_convert(milliseconds, ('datasets/' + foldername + '/test/benzin'), csv = True , label = 'benzin', ds_label = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 1389 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 179 files to spectrogram\n",
      "converted 35 files to spectrogram\n",
      "converted 610 files to spectrogram\n",
      "converted 32 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 1921 files to spectrogram\n",
      "converted 504 files to spectrogram\n",
      "converted 31 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 30 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 113 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 309 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 1280 files to spectrogram\n",
      "converted 11 files to spectrogram\n",
      "converted 198 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 290 files to spectrogram\n",
      "converted 33 files to spectrogram\n",
      "converted 431 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 3642 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 107 files to spectrogram\n",
      "converted 567 files to spectrogram\n",
      "converted 197 files to spectrogram\n",
      "converted 15 files to spectrogram\n",
      "converted 223 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 1454 files to spectrogram\n",
      "converted 61 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "Path to .csv: datasets/dataset1_1sec/train/diesel.csv\n"
     ]
    }
   ],
   "source": [
    "diesel_train.split_and_convert(milliseconds, ('datasets/' + foldername + '/train/diesel'), csv = True , label = 'diesel', ds_label = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 6 files to spectrogram\n",
      "converted 876 files to spectrogram\n",
      "converted 1483 files to spectrogram\n",
      "converted 19 files to spectrogram\n",
      "converted 1712 files to spectrogram\n",
      "converted 179 files to spectrogram\n",
      "converted 516 files to spectrogram\n",
      "Path to .csv: datasets/dataset1_1sec/valid/diesel.csv\n"
     ]
    }
   ],
   "source": [
    "diesel_valid.split_and_convert(milliseconds, ('datasets/' + foldername + '/valid/diesel'), csv = True , label = 'diesel', ds_label = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 492 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 41 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 1335 files to spectrogram\n",
      "converted 204 files to spectrogram\n",
      "converted 287 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "converted 27 files to spectrogram\n",
      "converted 6 files to spectrogram\n",
      "Path to .csv: datasets/dataset1_1sec/test/diesel.csv\n"
     ]
    }
   ],
   "source": [
    "diesel_test.split_and_convert(milliseconds, ('datasets/' + foldername + '/test/diesel'), csv = True , label = 'diesel', ds_label = 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
